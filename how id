[33mcommit 863010695c853091ed500f06e6b99d48acb098c4[m[33m ([m[1;36mHEAD -> [m[1;32mmain[m[33m)[m
Author: - <->
Date:   Mon Feb 21 21:21:54 2022 +0530

    commiting files

[1mdiff --git a/ResDense.py b/ResDense.py[m
[1mnew file mode 100644[m
[1mindex 0000000..c81f89f[m
[1m--- /dev/null[m
[1m+++ b/ResDense.py[m
[36m@@ -0,0 +1,125 @@[m
[32m+[m[32m#!/usr/bin/env python[m
[32m+[m[32m# coding: utf-8[m
[32m+[m
[32m+[m[32m# In[1]:[m
[32m+[m
[32m+[m
[32m+[m[32mimport os[m
[32m+[m[32mos.environ["CUDA_DEVICE_ORDER"]= "PCI_BUS_ID"[m
[32m+[m[32mos.environ["CUDA_VISIBLE_DEVICES"]= "0"[m
[32m+[m
[32m+[m[32mimport tensorflow as tf[m
[32m+[m[32mfrom tensorflow import keras[m
[32m+[m
[32m+[m
[32m+[m[32m# In[2]:[m
[32m+[m
[32m+[m
[32m+[m[32mDense = tf.keras.layers.Dense[m
[32m+[m[32mConv2D = tf.keras.layers.Conv2D[m
[32m+[m[32mMaxPooling2D = tf.keras.layers.MaxPooling2D[m
[32m+[m[32mMaxPool2D = tf.keras.layers.MaxPool2D[m
[32m+[m[32mFlatten = tf.keras.layers.Flatten[m
[32m+[m[32mDropout = tf.keras.layers.Dropout[m
[32m+[m[32mInput = tf.keras.layers.Input[m
[32m+[m[32mActivation = tf.keras.layers.Activation[m
[32m+[m[32mGlobalAveragePooling2D = tf.keras.layers.GlobalAveragePooling2D[m
[32m+[m[32mBatchNormalization = tf.keras.layers.BatchNormalization[m
[32m+[m[32mConcatenate= tf.keras.layers.Concatenate[m
[32m+[m
[32m+[m[32march = tf.keras.models.Model[m
[32m+[m
[32m+[m[32mtf.keras.backend.set_image_data_format('channels_last')[m
[32m+[m
[32m+[m
[32m+[m[32m# In[3]:[m
[32m+[m
[32m+[m
[32m+[m[32mDenseNet121 = tf.keras.applications.densenet.DenseNet121[m
[32m+[m[32mDensenet169 = tf.keras.applications.densenet.DenseNet169[m
[32m+[m[32mDensenet201 = tf.keras.applications.densenet.DenseNet201[m
[32m+[m
[32m+[m[32mResNet50 = tf.keras.applications.resnet.ResNet50[m
[32m+[m[32mResNet101 = tf.keras.applications.resnet.ResNet101[m
[32m+[m
[32m+[m[32mResNet50V2 = tf.keras.applications.resnet_v2.ResNet50V2[m
[32m+[m[32mResNet101V2 = tf.keras.applications.resnet_v2.ResNet101V2[m
[32m+[m
[32m+[m
[32m+[m[32m# In[9]:[m
[32m+[m
[32m+[m
[32m+[m[32mdef dense_block(x, blocks, name):[m
[32m+[m[32m    """A dense block.[m
[32m+[m[32m    # Arguments[m
[32m+[m[32m        x: input tensor.[m
[32m+[m[32m        blocks: integer, the number of building blocks.[m
[32m+[m[32m        name: string, block label.[m
[32m+[m[32m    # Returns[m
[32m+[m[32m        output tensor for the block.[m
[32m+[m[32m    """[m
[32m+[m[32m    for i in range(blocks):[m
[32m+[m[32m        x = conv_block(x, 32, name=name + '_block' + str(i + 1))[m
[32m+[m[32m    return x[m
[32m+[m
[32m+[m
[32m+[m[32m# In[8]:[m
[32m+[m
[32m+[m
[32m+[m[32mdef conv_block(x, growth_rate, name):[m
[32m+[m[32m    """A building block for a dense block.[m
[32m+[m[32m    # Arguments[m
[32m+[m[32m        x: input tensor.[m
[32m+[m[32m        growth_rate: float, growth rate at dense layers.[m
[32m+[m[32m        name: string, block label.[m
[32m+[m[32m    # Returns[m
[32m+[m[32m        Output tensor for the block.[m
[32m+[m[32m    """[m
[32m+[m[32m    bn_axis = 3 #if backend.image_data_format() == 'channels_last' else 1[m
[32m+[m[32m    x1 = BatchNormalization(axis=bn_axis,[m
[32m+[m[32m                                   epsilon=1.001e-5,[m
[32m+[m[32m                                   name=name + '_0_bn')(x)[m
[32m+[m[32m    x1 = Activation('relu', name=name + '_0_relu')(x1)[m
[32m+[m[32m    x1 = Conv2D(4 * growth_rate, 1,[m
[32m+[m[32m                       use_bias=False,[m
[32m+[m[32m                       name=name + '_1_conv')(x1)[m
[32m+[m[32m    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,[m
[32m+[m[32m                                   name=name + '_1_bn')(x1)[m
[32m+[m[32m    x1 = Activation('relu', name=name + '_1_relu')(x1)[m
[32m+[m[32m    x1 = Conv2D(growth_rate, 3,[m
[32m+[m[32m                       padding='same',[m
[32m+[m[32m                       use_bias=False,[m
[32m+[m[32m                       name=name + '_2_conv')(x1)[m
[32m+[m[32m    x = Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])[m
[32m+[m[32m    return x[m
[32m+[m
[32m+[m
[32m+[m[32m# In[7]:[m
[32m+[m
[32m+[m
[32m+[m[32mdef model_one_class([m
[32m+[m[32m        input_shape = (224,224,3),[m
[32m+[m[32m        class_6=6,[m
[32m+[m[32m        class_20=20,[m
[32m+[m[32m        class_82=75):[m
[32m+[m[32m    # for results of sota papers[m
[32m+[m[32m    inp = Input(input_shape)[m
[32m+[m[32m    base_model= DenseNet121(include_top=False, weights=None, input_tensor = inp, backend = tf.keras.backend , layers = tf.keras.layers , models = tf.keras.models , utils = tf.keras.utils)[m
[32m+[m[41m    [m
[32m+[m[32m    x =  base_model.output[m
[32m+[m[32m    x = GlobalAveragePooling2D()(x)[m
[32m+[m[32m    x = Dense(class_82, activation='softmax')(x)[m
[32m+[m
[32m+[m[32m    model = arch(inputs=inp, outputs= [x])[m
[32m+[m
[32m+[m[32m    for layer in base_model.layers:[m
[32m+[m[32m        layer.trainable = True[m
[32m+[m[41m    [m
[32m+[m[32m    return model[m
[32m+[m
[32m+[m
[32m+[m[32m# In[ ]:[m
[32m+[m
[32m+[m
[32m+[m
[32m+[m
[1mdiff --git a/ResDes.py b/ResDes.py[m
[1mnew file mode 100644[m
[1mindex 0000000..0188ea4[m
[1m--- /dev/null[m
[1m+++ b/ResDes.py[m
[36m@@ -0,0 +1,125 @@[m
[32m+[m[32m#!/usr/bin/env python[m
[32m+[m[32m# coding: utf-8[m
[32m+[m
[32m+[m[32m# In[1]:[m
[32m+[m
[32m+[m
[32m+[m[32mimport os[m
[32m+[m[32mos.environ["CUDA_DEVICE_ORDER"]= "PCI_BUS_ID"[m
[32m+[m[32mos.environ["CUDA_VISIBLE_DEVICES"]= "0"[m
[32m+[m
[32m+[m[32mimport tensorflow as tf[m
[32m+[m[32mfrom tensorflow import keras[m
[32m+[m
[32m+[m
[32m+[m[32m# In[2]:[m
[32m+[m
[32m+[m
[32m+[m[32mDense = tf.keras.layers.Dense[m
[32m+[m[32mConv2D = tf.keras.layers.Conv2D[m
[32m+[m[32mMaxPooling2D = tf.keras.layers.MaxPooling2D[m
[32m+[m[32mMaxPool2D = tf.keras.layers.MaxPool2D[m
[32m+[m[32mFlatten = tf.keras.layers.Flatten[m
[32m+[m[32mDropout = tf.keras.layers.Dropout[m
[32m+[m[32mInput = tf.keras.layers.Input[m
[32m+[m[32mActivation = tf.keras.layers.Activation[m
[32m+[m[32mGlobalAveragePooling2D = tf.keras.layers.GlobalAveragePooling2D[m
[32m+[m[32mBatchNormalization = tf.keras.layers.BatchNormalization[m
[32m+[m[32mConcatenate= tf.keras.layers.Concatenate[m
[32m+[m
[32m+[m[32march = tf.keras.models.Model[m
[32m+[m
[32m+[m[32mtf.keras.backend.set_image_data_format('channels_last')[m
[32m+[m
[32m+[m
[32m+[m[32m# In[3]:[m
[32m+[m
[32m+[m
[32m+[m[32mDenseNet121 = tf.keras.applications.densenet.DenseNet121[m
[32m+[m[32mDensenet169 = tf.keras.applications.densenet.DenseNet169[m
[32m+[m[32mDensenet201 = tf.keras.applications.densenet.DenseNet201[m
[32m+[m
[32m+[m[32mResNet50 = tf.keras.applications.resnet.ResNet50[m
[32m+[m[32mResNet101 = tf.keras.applications.resnet.ResNet101[m
[32m+[m
[32m+[m[32mResNet50V2 = tf.keras.applications.resnet_v2.ResNet50V2[m
[32m+[m[32mResNet101V2 = tf.keras.applications.resnet_v2.ResNet101V2[m
[32m+[m
[32m+[m
[32m+[m[32m# In[4]:[m
[32m+[m
[32m+[m
[32m+[m[32mdef dense_block(x, blocks, name):[m
[32m+[m[32m    """A dense block.[m
[32m+[m[32m    # Arguments[m
[32m+[m[32m        x: input tensor.[m
[32m+[m[32m        blocks: integer, the number of building blocks.[m
[32m+[m[32m        name: string, block label.[m
[32m+[m[32m    # Returns[m
[32m+[m[32m        output tensor for the block.[m
[32m+[m[32m    """[m
[32m+[m[32m    for i in range(blocks):[m
[32m+[m[32m        x = conv_block(x, 32, name=name + '_block' + str(i + 1))[m
[32m+[m[32m    return x[m
[32m+[m
[32m+[m
[32m+[m[32m# In[5]:[m
[32m+[m
[32m+[m
[32m+[m[32mdef conv_block(x, growth_rate, name):[m
[32m+[m[32m    """A